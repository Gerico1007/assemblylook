

All right, so this is a completely different method. In that there is actually no input IME, I wonder what it is, input method editor or something like that. There is none. The user is actually talking to, well, to mp3 file.

There is nothing to press, there is nothing to type, there is no timer, there is no worry that something may be misheard. Well, okay, there is a worry that it can be misheard, but there is no worry about timers ticking, about interface disappearing, about files go missing or text, there is almost none. Why is this so? Because the user pressed Audio Recorder, that is, selected Audio Recorder, the actual just very common application for Android, pressed Record,

Yes, there is a timer ticking, but it is not scary this time. And user can talk to users hard content, freely expressing the thoughts. How come that Gemini AI is actually seeing it as text? Well, there is a mystery. Because many years ago, I think three, user learned how LLM, the actual application LLM, works in Android. It is a very robust and universal thing which can transcribe voices, which can actually talk. There are offline large language models. Well, it can do, I think, everything that the same application can do on a huge server only, server computers.

So user is not analyzing images, which also can be done this. User is not writing poetry with this offline LLMs, but using WhisperX, which is a specialized audio model, or is it Whisper? I think it's the same actually, but the application's called WhisperX. So using this, user is going to transcribe this very text, well, it's the text, this very audio, into a, well, a regular, regular file. Actually, you know what? Ha, I know. I can switch on, yes, I think I can switch on even the time codes. Yes, there will be time codes and I think each sentence will be separate and time coded. But I must remember not to switch the higherization, another option of WhisperX, because then it takes three times as long. So let me see. This is three minutes, 40 seconds long. So it would be, I think, four minutes by the time I finish. And it's likely to take twice as much. So either 8 up to 12 minutes to transcribe using, I think, medium or small quality, which is good enough trade-off between quality and time and also the requirements of the device, because large language model is actually, sorry, large audio model, the largest, I think is large V3, is actually crashing Android unless one is very cunless one is very careful. Thank you. See you soon.
